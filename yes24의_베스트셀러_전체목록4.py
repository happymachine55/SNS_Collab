# -*- coding: utf-8 -*-
"""yes24의 베스트셀러 전체목록4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v74BRXO6Bgc1Yx845KI77ZNBUwhZe3ak
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

"""한페이지"""

# 1) 웹페이지 접근해서 정보를 가져와야함 => response 객체 => html 페이지
url = 'https://www.yes24.com/product/category/bestseller?categoryNumber=001&pageNumber=1&pageSize=120'
res = requests.get(url)
html_str = res.text
print(res)  # <Response [200]>

# 2) 뷰티풀 숩 객체화
# html 페이지 => 숩객체

soup = BeautifulSoup(html_str, 'html.parser')
# soup

# 3) 소스 파악
# 크롬개발자 모드 : f12 , ctrl+shift+i

# 4) 순위 정보 추출
# 전체 베스트셀러 페이지에서 순위 정보 추출
# data-goods-no 속성을 가진 li 태그 리스트로 받는다
target = soup.select('li[data-goods-no]')

print(len(target))         # 해당 페이지의 책 개수 (예: 20, 40, 120 등)
print(target[0])          # 1위 책 정보
print()
print(target[-1])         # 마지막 책 정보
print()

# 5) 1위에서 개별 정보 추출
# 순위, 책제목, 저자, 출판사

print('순위 → ', target[0].select_one('em.ico.rank').text.strip() if target[0].select_one('em.ico.rank') else '')
print('책 제목 → ', target[0].select_one('a.gd_name').text.strip() if target[0].select_one('a.gd_name') else '')
print('저자 → ', target[0].select_one('span.info_auth').text.strip() if target[0].select_one('span.info_auth') else '')
print('출판사 → ', target[0].select_one('span.info_pub').text.strip() if target[0].select_one('span.info_pub') else '')

# 6) 2차원 리스트 구조로 변경 (전체 페이지 크롤링)

# 빈리스트 생성
bestbook_list = []
for a in target:
    # 순위: li 태그 내 strong.num 또는 li의 순서
    순위 = a.select_one('em.ico.rank').text.strip() if a.select_one('em.ico.rank') else ''
    # 책제목: .gd_name 클래스
    책제목 = a.select_one('a.gd_name').text.strip() if a.select_one('a.gd_name') else ''
    # 저자: .info_auth 클래스
    저자 = a.select_one('span.info_auth').text.strip() if a.select_one('span.info_auth') else ''
    # 출판사: .info_pub 클래스
    출판사 = a.select_one('span.info_pub').text.strip() if a.select_one('span.info_pub') else ''
    print(순위, 책제목, 저자, 출판사)
    bestbook_list.append([순위, 책제목, 저자, 출판사])

# 데이터프레임
pd.DataFrame(bestbook_list, columns=['순위', '책제목', '저자', '출판사'])
df = pd.DataFrame(bestbook_list, columns=['순위', '책제목', '저자', '출판사'])
df

from google.colab import sheets
sheet = sheets.InteractiveSheet(df=df)

"""여러페이지"""

# 7) 2차원 리스트 구조로 변경 (전체 페이지 크롤링)

# 빈리스트 생성
bestbook_list = []
for page in range(1, 11):  # 원하는 전체 페이지 수로 조정 (예: 10페이지면 range(1, 11))
    url = f'https://www.yes24.com/Product/Category/BestSeller?categoryNumber=001&pageNumber={page}&pageSize=120'
    res = requests.get(url)
    soup = BeautifulSoup(res.text, 'html.parser')
    target = soup.select('li[data-goods-no]')
    if not target:
        break  # 더 이상 데이터가 없으면 종료
    for a in target:
        순위 = a.select_one('em.ico.rank').text.strip() if a.select_one('em.ico.rank') else ''
        책제목 = a.select_one('a.gd_name').text.strip() if a.select_one('a.gd_name') else ''
        저자 = a.select_one('span.info_auth').text.strip() if a.select_one('span.info_auth') else ''
        출판사 = a.select_one('span.info_pub').text.strip() if a.select_one('span.info_pub') else ''
        print(순위, 책제목, 저자, 출판사)
        bestbook_list.append([순위, 책제목, 저자, 출판사])

# 데이터프레임
pd.DataFrame(bestbook_list, columns=['순위', '책제목', '저자', '출판사'])
df = pd.DataFrame(bestbook_list, columns=['순위', '책제목', '저자', '출판사'])
df

from google.colab import sheets
sheet = sheets.InteractiveSheet(df=df)

